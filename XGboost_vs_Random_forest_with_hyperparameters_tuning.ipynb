{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **#XGboost vs Random forest with hyperparameters tuning**"
      ],
      "metadata": {
        "id": "i8cyEZjREAFN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7YZ-z3EDkRL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Load the diamonds dataset\n",
        "\n",
        "diamonds_df = sns.load_dataset('diamonds')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X = diamonds_df.drop('price', axis=1)\n",
        "\n",
        "y = diamonds_df['price']\n",
        "\n",
        "#label encoding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "X['cut'] = le.fit_transform(X['cut'])\n",
        "\n",
        "X['color'] = le.fit_transform(X['color']) \n",
        "\n",
        "X['clarity'] = le.fit_transform(X['clarity'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the models\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "\n",
        "models = {'Random Forest': rf, 'XGBoost': xgb}\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "     model.fit(X_train, y_train)\n",
        "\n",
        "     y_pred = model.predict(X_test) \n",
        "\n",
        "     mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Define the models\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42) \n",
        "xgb = XGBRegressor(random_state=42)\n",
        "\n",
        "# hyper parameters of these models\n",
        "\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "     'max_depth': [10, 20, 30],\n",
        "     'min_samples_split': [2, 5, 10],\n",
        "     'min_samples_leaf': [1, 2, 4]\n",
        "\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "\n",
        "     'n_estimators': [100, 300, 500],\n",
        "      'max_depth': [3, 5, 7],\n",
        "      'learning_rate': [0.1, 0.01, 0.001],\n",
        "      'subsample': [0.6, 0.8, 1],\n",
        "      'colsample_bytree': [0.6, 0.8, 1]\n",
        "}\n",
        "# Perform grid search to find the best hyperparameters for each model\n",
        "\n",
        "rf_gs = GridSearchCV(rf, rf_params, scoring='neg_mean_squared_error', cv=5)\n",
        "\n",
        "rf_gs.fit(X_train, y_train)\n",
        "\n",
        "rf_best = rf_gs.best_estimator_\n",
        "\n",
        "xgb_gs = GridSearchCV(xgb, xgb_params, scoring='neg_mean_squared_error', cv=5)\n",
        "xgb_gs.fit(X_train, y_train)\n",
        "xgb_best = xgb_gs.best_estimator__\n",
        "\n",
        "\n",
        "# Evaluate the best models on the testing set\n",
        "\n",
        "rf_pred = rf_best.predict(X_test)\n",
        "\n",
        "rf_mse = np.mean ((rf_pred - y_test) ** 2)\n",
        "\n",
        "print(f'Random Forest - MSE: {rf_mse:.2f}')\n",
        "\n",
        "xgb_pred = xgb_best.predict(X_test)\n",
        "\n",
        "xgb_mse = np.mean((xgb_pred - y_test) ** 2) \n",
        "\n",
        "print(f'XGBoost - MSE: {xgb_mse:.2f}')\n",
        "\n",
        "\n"
      ]
    }
  ]
}